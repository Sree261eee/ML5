{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from matplotlib import pyplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/Administrator/PycharmProjects/pythonProject2/ML5/code/Sentiment.csv')\n",
    "\n",
    "# Keeping only the neccessary columns\n",
    "data = data[['text','sentiment']]\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text'] = data['text'].apply(lambda x: x.lower())\n",
    "data['text'] = data['text'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13871, 28)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel():\n",
    "  embed_dim=128\n",
    "  lstm_out=196\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "  model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(Dense(3,activation='softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "  return model\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "integer_encoded = labelencoder.fit_transform(data['sentiment'])\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         Neutral\n",
      "1        Positive\n",
      "2         Neutral\n",
      "3        Positive\n",
      "4        Positive\n",
      "           ...   \n",
      "13866    Negative\n",
      "13867    Positive\n",
      "13868    Positive\n",
      "13869    Negative\n",
      "13870    Positive\n",
      "Name: sentiment, Length: 13871, dtype: object\n",
      "[1 2 1 ... 2 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(data['sentiment'])\n",
    "print(integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "291/291 - 38s - loss: 0.8258 - accuracy: 0.6419\n",
      "Epoch 2/20\n",
      "291/291 - 34s - loss: 0.6822 - accuracy: 0.7087\n",
      "Epoch 3/20\n",
      "291/291 - 32s - loss: 0.6077 - accuracy: 0.7451\n",
      "Epoch 4/20\n",
      "291/291 - 31s - loss: 0.5610 - accuracy: 0.7648\n",
      "Epoch 5/20\n",
      "291/291 - 32s - loss: 0.5133 - accuracy: 0.7892\n",
      "Epoch 6/20\n",
      "291/291 - 32s - loss: 0.4730 - accuracy: 0.8034\n",
      "Epoch 7/20\n",
      "291/291 - 32s - loss: 0.4344 - accuracy: 0.8261\n",
      "Epoch 8/20\n",
      "291/291 - 32s - loss: 0.3984 - accuracy: 0.8407\n",
      "Epoch 9/20\n",
      "291/291 - 32s - loss: 0.3641 - accuracy: 0.8549\n",
      "Epoch 10/20\n",
      "291/291 - 32s - loss: 0.3405 - accuracy: 0.8604\n",
      "Epoch 11/20\n",
      "291/291 - 33s - loss: 0.3166 - accuracy: 0.8727\n",
      "Epoch 12/20\n",
      "291/291 - 32s - loss: 0.3053 - accuracy: 0.8768\n",
      "Epoch 13/20\n",
      "291/291 - 32s - loss: 0.2833 - accuracy: 0.8880\n",
      "Epoch 14/20\n",
      "291/291 - 32s - loss: 0.2713 - accuracy: 0.8914\n",
      "Epoch 15/20\n",
      "291/291 - 33s - loss: 0.2656 - accuracy: 0.8917\n",
      "Epoch 16/20\n",
      "291/291 - 32s - loss: 0.2461 - accuracy: 0.8981\n",
      "Epoch 17/20\n",
      "291/291 - 32s - loss: 0.2372 - accuracy: 0.9020\n",
      "Epoch 18/20\n",
      "291/291 - 32s - loss: 0.2259 - accuracy: 0.9056\n",
      "Epoch 19/20\n",
      "291/291 - 32s - loss: 0.2297 - accuracy: 0.9048\n",
      "Epoch 20/20\n",
      "291/291 - 32s - loss: 0.2141 - accuracy: 0.9112\n",
      "144/144 - 2s - loss: 1.9280 - accuracy: 0.6457\n",
      "1.9280064105987549\n",
      "0.6456968188285828\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model = createmodel()\n",
    "model.fit(X_train, Y_train, epochs = 20, batch_size=batch_size, verbose = 2)\n",
    "score,acc = model.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
    "print(score)\n",
    "print(acc)\n",
    "print(model.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL SAVED\n",
    "model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACTING MODEL\n",
    "from keras.models import load_model\n",
    "model_save= load_model('/Users/Administrator/PycharmProjects/pythonProject2/ML5/code/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Administrator\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positve\n"
     ]
    }
   ],
   "source": [
    "# PREDICTING GIVEN RESULTS\n",
    "import numpy as np\n",
    "sentence = ['A lot of good things are happening. We are respected again throughout the world, and that is a great thing']\n",
    "#vectorizing the tweet by the pre-fitted tokenizer instance\n",
    "sentence = tokenizer.texts_to_sequences(sentence)\n",
    "#padding the tweet to have exactly the same shape as `embedding_2` input\n",
    "sentence = pad_sequences(sentence, maxlen=28, dtype='int32', value=0)\n",
    "\n",
    "sentiment = model_save.predict_classes(sentence,batch_size=1)[0]\n",
    "\n",
    "\n",
    "if sentiment == 0:\n",
    "  print(\"negative\")\n",
    "elif sentiment==1:\n",
    "     print(\"neutral\")\n",
    "else:\n",
    "        print(\"positve\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 - 27s - loss: 0.8401 - accuracy: 0.6337\n",
      "47/47 - 2s - loss: 0.7581 - accuracy: 0.6579\n",
      "186/186 - 27s - loss: 0.8484 - accuracy: 0.6324\n",
      "47/47 - 1s - loss: 0.7906 - accuracy: 0.6686\n",
      "186/186 - 28s - loss: 0.8433 - accuracy: 0.6347\n",
      "47/47 - 1s - loss: 0.7749 - accuracy: 0.6708\n",
      "186/186 - 28s - loss: 0.8425 - accuracy: 0.6367\n",
      "47/47 - 1s - loss: 0.7655 - accuracy: 0.6706\n",
      "186/186 - 28s - loss: 0.8533 - accuracy: 0.6330\n",
      "47/47 - 1s - loss: 0.7760 - accuracy: 0.6674\n",
      "Epoch 1/2\n",
      "186/186 - 28s - loss: 0.8499 - accuracy: 0.6338\n",
      "Epoch 2/2\n",
      "186/186 - 24s - loss: 0.6994 - accuracy: 0.7031\n",
      "47/47 - 1s - loss: 0.7240 - accuracy: 0.6912\n",
      "Epoch 1/2\n",
      "186/186 - 27s - loss: 0.8434 - accuracy: 0.6381\n",
      "Epoch 2/2\n",
      "186/186 - 24s - loss: 0.6961 - accuracy: 0.7016\n",
      "47/47 - 1s - loss: 0.7430 - accuracy: 0.6703\n",
      "Epoch 1/2\n",
      "186/186 - 27s - loss: 0.8498 - accuracy: 0.6326\n",
      "Epoch 2/2\n",
      "186/186 - 25s - loss: 0.6891 - accuracy: 0.7073\n",
      "47/47 - 1s - loss: 0.7448 - accuracy: 0.6896\n",
      "Epoch 1/2\n",
      "186/186 - 27s - loss: 0.8598 - accuracy: 0.6293\n",
      "Epoch 2/2\n",
      "186/186 - 24s - loss: 0.6926 - accuracy: 0.7009\n",
      "47/47 - 1s - loss: 0.7469 - accuracy: 0.6674\n",
      "Epoch 1/2\n",
      "186/186 - 28s - loss: 0.8464 - accuracy: 0.6321\n",
      "Epoch 2/2\n",
      "186/186 - 25s - loss: 0.6809 - accuracy: 0.7126\n",
      "47/47 - 1s - loss: 0.7764 - accuracy: 0.6776\n",
      "Epoch 1/3\n",
      "186/186 - 27s - loss: 0.8536 - accuracy: 0.6312\n",
      "Epoch 2/3\n",
      "186/186 - 24s - loss: 0.7037 - accuracy: 0.6999\n",
      "Epoch 3/3\n",
      "186/186 - 24s - loss: 0.6175 - accuracy: 0.7448\n",
      "47/47 - 1s - loss: 0.7412 - accuracy: 0.6799\n",
      "Epoch 1/3\n",
      "186/186 - 27s - loss: 0.8494 - accuracy: 0.6381\n",
      "Epoch 2/3\n",
      "186/186 - 26s - loss: 0.6925 - accuracy: 0.7065\n",
      "Epoch 3/3\n",
      "186/186 - 26s - loss: 0.6138 - accuracy: 0.7446\n",
      "47/47 - 2s - loss: 0.7444 - accuracy: 0.6821\n",
      "Epoch 1/3\n",
      "186/186 - 27s - loss: 0.8428 - accuracy: 0.6328\n",
      "Epoch 2/3\n",
      "186/186 - 24s - loss: 0.6838 - accuracy: 0.7070\n",
      "Epoch 3/3\n",
      "186/186 - 24s - loss: 0.6107 - accuracy: 0.7444\n",
      "47/47 - 1s - loss: 0.7474 - accuracy: 0.6859\n",
      "Epoch 1/3\n",
      "186/186 - 27s - loss: 0.8443 - accuracy: 0.6348\n",
      "Epoch 2/3\n",
      "186/186 - 25s - loss: 0.6845 - accuracy: 0.7050\n",
      "Epoch 3/3\n",
      "186/186 - 27s - loss: 0.6100 - accuracy: 0.7426\n",
      "47/47 - 2s - loss: 0.7686 - accuracy: 0.6749\n",
      "Epoch 1/3\n",
      "186/186 - 27s - loss: 0.8423 - accuracy: 0.6370\n",
      "Epoch 2/3\n",
      "186/186 - 25s - loss: 0.6775 - accuracy: 0.7127\n",
      "Epoch 3/3\n",
      "186/186 - 25s - loss: 0.6038 - accuracy: 0.7477\n",
      "47/47 - 1s - loss: 0.7937 - accuracy: 0.6625\n",
      "149/149 - 25s - loss: 0.8612 - accuracy: 0.6295\n",
      "38/38 - 1s - loss: 0.7701 - accuracy: 0.6579\n",
      "149/149 - 24s - loss: 0.8612 - accuracy: 0.6299\n",
      "38/38 - 1s - loss: 0.7942 - accuracy: 0.6638\n",
      "149/149 - 24s - loss: 0.8537 - accuracy: 0.6273\n",
      "38/38 - 1s - loss: 0.7671 - accuracy: 0.6697\n",
      "149/149 - 24s - loss: 0.8626 - accuracy: 0.6296\n",
      "38/38 - 1s - loss: 0.7710 - accuracy: 0.6722\n",
      "149/149 - 24s - loss: 0.8472 - accuracy: 0.6320\n",
      "38/38 - 2s - loss: 0.7804 - accuracy: 0.6706\n",
      "Epoch 1/2\n",
      "149/149 - 24s - loss: 0.8583 - accuracy: 0.6303\n",
      "Epoch 2/2\n",
      "149/149 - 21s - loss: 0.6966 - accuracy: 0.7024\n",
      "38/38 - 1s - loss: 0.7245 - accuracy: 0.6772\n",
      "Epoch 1/2\n",
      "149/149 - 26s - loss: 0.8424 - accuracy: 0.6359\n",
      "Epoch 2/2\n",
      "149/149 - 22s - loss: 0.6952 - accuracy: 0.7070\n",
      "38/38 - 2s - loss: 0.7371 - accuracy: 0.6826\n",
      "Epoch 1/2\n",
      "149/149 - 25s - loss: 0.8528 - accuracy: 0.6342\n",
      "Epoch 2/2\n",
      "149/149 - 22s - loss: 0.6906 - accuracy: 0.7015\n",
      "38/38 - 1s - loss: 0.7505 - accuracy: 0.6918\n",
      "Epoch 1/2\n",
      "149/149 - 24s - loss: 0.8622 - accuracy: 0.6291\n",
      "Epoch 2/2\n",
      "149/149 - 21s - loss: 0.6972 - accuracy: 0.7030\n",
      "38/38 - 1s - loss: 0.7380 - accuracy: 0.6792\n",
      "Epoch 1/2\n",
      "149/149 - 24s - loss: 0.8456 - accuracy: 0.6332\n",
      "Epoch 2/2\n",
      "149/149 - 23s - loss: 0.6842 - accuracy: 0.7060\n",
      "38/38 - 1s - loss: 0.7831 - accuracy: 0.6706\n",
      "Epoch 1/3\n",
      "149/149 - 24s - loss: 0.8514 - accuracy: 0.6318\n",
      "Epoch 2/3\n",
      "149/149 - 22s - loss: 0.6947 - accuracy: 0.7065\n",
      "Epoch 3/3\n",
      "149/149 - 22s - loss: 0.6170 - accuracy: 0.7363\n",
      "38/38 - 1s - loss: 0.7427 - accuracy: 0.6896\n",
      "Epoch 1/3\n",
      "149/149 - 25s - loss: 0.8452 - accuracy: 0.6347\n",
      "Epoch 2/3\n",
      "149/149 - 23s - loss: 0.6933 - accuracy: 0.7058\n",
      "Epoch 3/3\n",
      "149/149 - 38s - loss: 0.6222 - accuracy: 0.7369\n",
      "38/38 - 2s - loss: 0.7764 - accuracy: 0.6891\n",
      "Epoch 1/3\n",
      "149/149 - 41s - loss: 0.8474 - accuracy: 0.6345\n",
      "Epoch 2/3\n",
      "149/149 - 35s - loss: 0.6824 - accuracy: 0.7160\n",
      "Epoch 3/3\n",
      "149/149 - 37s - loss: 0.6088 - accuracy: 0.7441\n",
      "38/38 - 2s - loss: 0.7554 - accuracy: 0.6923\n",
      "Epoch 1/3\n",
      "149/149 - 41s - loss: 0.8588 - accuracy: 0.6293\n",
      "Epoch 2/3\n",
      "149/149 - 37s - loss: 0.6923 - accuracy: 0.7053\n",
      "Epoch 3/3\n",
      "149/149 - 36s - loss: 0.6090 - accuracy: 0.7391\n",
      "38/38 - 2s - loss: 0.7792 - accuracy: 0.6830\n",
      "Epoch 1/3\n",
      "149/149 - 38s - loss: 0.8518 - accuracy: 0.6359\n",
      "Epoch 2/3\n",
      "149/149 - 34s - loss: 0.6805 - accuracy: 0.7141\n",
      "Epoch 3/3\n",
      "149/149 - 35s - loss: 0.6025 - accuracy: 0.7497\n",
      "38/38 - 2s - loss: 0.8204 - accuracy: 0.6674\n",
      "124/124 - 37s - loss: 0.8595 - accuracy: 0.6274\n",
      "31/31 - 2s - loss: 0.7580 - accuracy: 0.6665\n",
      "124/124 - 35s - loss: 0.8552 - accuracy: 0.6285\n",
      "31/31 - 2s - loss: 0.7865 - accuracy: 0.6622\n",
      "124/124 - 37s - loss: 0.8625 - accuracy: 0.6299\n",
      "31/31 - 2s - loss: 0.7623 - accuracy: 0.6767\n",
      "124/124 - 36s - loss: 0.8604 - accuracy: 0.6339\n",
      "31/31 - 2s - loss: 0.7758 - accuracy: 0.6701\n",
      "124/124 - 42s - loss: 0.8520 - accuracy: 0.6344\n",
      "31/31 - 2s - loss: 0.7859 - accuracy: 0.6668\n",
      "Epoch 1/2\n",
      "124/124 - 38s - loss: 0.8599 - accuracy: 0.6321\n",
      "Epoch 2/2\n",
      "124/124 - 33s - loss: 0.7001 - accuracy: 0.7014\n",
      "31/31 - 2s - loss: 0.7253 - accuracy: 0.6740\n",
      "Epoch 1/2\n",
      "124/124 - 38s - loss: 0.8511 - accuracy: 0.6308\n",
      "Epoch 2/2\n",
      "124/124 - 34s - loss: 0.6997 - accuracy: 0.7035\n",
      "31/31 - 2s - loss: 0.7549 - accuracy: 0.6638\n",
      "Epoch 1/2\n",
      "124/124 - 36s - loss: 0.8529 - accuracy: 0.6271\n",
      "Epoch 2/2\n",
      "124/124 - 33s - loss: 0.6972 - accuracy: 0.6990\n",
      "31/31 - 2s - loss: 0.7474 - accuracy: 0.6799\n",
      "Epoch 1/2\n",
      "124/124 - 39s - loss: 0.8659 - accuracy: 0.6253\n",
      "Epoch 2/2\n",
      "124/124 - 34s - loss: 0.6971 - accuracy: 0.7034\n",
      "31/31 - 2s - loss: 0.7328 - accuracy: 0.6825\n",
      "Epoch 1/2\n",
      "124/124 - 37s - loss: 0.8702 - accuracy: 0.6254\n",
      "Epoch 2/2\n",
      "124/124 - 33s - loss: 0.6993 - accuracy: 0.7024\n",
      "31/31 - 2s - loss: 0.7709 - accuracy: 0.6690\n",
      "Epoch 1/3\n",
      "124/124 - 38s - loss: 0.8667 - accuracy: 0.6262\n",
      "Epoch 2/3\n",
      "124/124 - 33s - loss: 0.7074 - accuracy: 0.6969\n",
      "Epoch 3/3\n",
      "124/124 - 34s - loss: 0.6261 - accuracy: 0.7396\n",
      "31/31 - 2s - loss: 0.7418 - accuracy: 0.6853\n",
      "Epoch 1/3\n",
      "124/124 - 37s - loss: 0.8566 - accuracy: 0.6328\n",
      "Epoch 2/3\n",
      "124/124 - 33s - loss: 0.7020 - accuracy: 0.7019\n",
      "Epoch 3/3\n",
      "124/124 - 33s - loss: 0.6183 - accuracy: 0.7440\n",
      "31/31 - 2s - loss: 0.7595 - accuracy: 0.6902\n",
      "Epoch 1/3\n",
      "124/124 - 39s - loss: 0.8552 - accuracy: 0.6260\n",
      "Epoch 2/3\n",
      "124/124 - 34s - loss: 0.6952 - accuracy: 0.7007\n",
      "Epoch 3/3\n",
      "124/124 - 35s - loss: 0.6151 - accuracy: 0.7378\n",
      "31/31 - 2s - loss: 0.7542 - accuracy: 0.6998\n",
      "Epoch 1/3\n",
      "124/124 - 38s - loss: 0.8649 - accuracy: 0.6307\n",
      "Epoch 2/3\n",
      "124/124 - 35s - loss: 0.7082 - accuracy: 0.7006\n",
      "Epoch 3/3\n",
      "124/124 - 36s - loss: 0.6145 - accuracy: 0.7403\n",
      "31/31 - 2s - loss: 0.7590 - accuracy: 0.6873\n",
      "Epoch 1/3\n",
      "124/124 - 39s - loss: 0.8623 - accuracy: 0.6296\n",
      "Epoch 2/3\n",
      "124/124 - 34s - loss: 0.6915 - accuracy: 0.7046\n",
      "Epoch 3/3\n",
      "124/124 - 32s - loss: 0.6025 - accuracy: 0.7463\n",
      "31/31 - 2s - loss: 0.7976 - accuracy: 0.6712\n",
      "Epoch 1/3\n",
      "155/155 - 47s - loss: 0.8413 - accuracy: 0.6369\n",
      "Epoch 2/3\n",
      "155/155 - 42s - loss: 0.6906 - accuracy: 0.7029\n",
      "Epoch 3/3\n",
      "155/155 - 42s - loss: 0.6253 - accuracy: 0.7332\n",
      "Best: 0.686752 using {'batch_size': 60, 'epochs': 3}\n"
     ]
    }
   ],
   "source": [
    "# 2. GRID SEARCH\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# model = createmodel()\n",
    "model = KerasClassifier(build_fn=createmodel,verbose=2)\n",
    "batch_size= [40, 50, 60]\n",
    "epochs = [1, 2, 3]\n",
    "param_grid= dict(batch_size=batch_size, epochs=epochs)\n",
    "grid  = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "grid_result= grid.fit(X_train, y=Y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Text Classification On spam.csv\n",
    "\n",
    "data1 = pd.read_csv('/Users/Administrator/PycharmProjects/pythonProject2/ML5/code/spam.csv',encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Keeping only the neccessary columns\n",
    "data1 = data1[['v1','v2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1['v2'] = data1['v2'].apply(lambda x: x.lower())\n",
    "data1['v2'] = data1['v2'].apply((lambda x: re.sub('[^a-zA-z0-9\\s]', '', x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in data1.iterrows():\n",
    "    row[0] = row[0].replace('rt', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "max_fatures = 2000\n",
    "tokenizer = Tokenizer(num_words=max_fatures, split=' ')\n",
    "tokenizer.fit_on_texts(data1['v2'].values)\n",
    "X = tokenizer.texts_to_sequences(data1['v2'].values)\n",
    "\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelencoder = LabelEncoder()\n",
    "integer_encoded = labelencoder.fit_transform(data1['v1'])\n",
    "y = to_categorical(integer_encoded)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size = 0.33, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createmodel1():\n",
    "  embed_dim=128\n",
    "  lstm_out=196\n",
    "  model = Sequential()\n",
    "  model.add(Embedding(max_fatures, embed_dim,input_length = X.shape[1]))\n",
    "  model.add(LSTM(lstm_out, dropout=0.2, recurrent_dropout=0.2))\n",
    "  model.add(Dense(2,activation='softmax'))\n",
    "  model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "117/117 - 81s - loss: 0.1712 - accuracy: 0.9424\n",
      "Epoch 2/5\n",
      "117/117 - 82s - loss: 0.0380 - accuracy: 0.9882\n",
      "Epoch 3/5\n",
      "117/117 - 122s - loss: 0.0191 - accuracy: 0.9946\n",
      "Epoch 4/5\n",
      "117/117 - 125s - loss: 0.0109 - accuracy: 0.9973\n",
      "Epoch 5/5\n",
      "117/117 - 143s - loss: 0.0048 - accuracy: 0.9984\n",
      "58/58 - 9s - loss: 0.1027 - accuracy: 0.9837\n",
      "0.10268498212099075\n",
      "0.9836868047714233\n",
      "['loss', 'accuracy']\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "model1 = createmodel1()\n",
    "model1.fit(X_train, Y_train, epochs = 5, batch_size=batch_size, verbose = 2)\n",
    "score,acc = model1.evaluate(X_test,Y_test,verbose=2,batch_size=batch_size)\n",
    "print(score)\n",
    "print(acc)\n",
    "print(model1.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
